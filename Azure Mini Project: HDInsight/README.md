# Overview <br>
Today, data is being generated and stored in staggering amounts at unprecedented
velocities. To make things more complicated, this data is generated in an ever-expanding
variety of formats.
In order to gain actionable insights into Big Data sources, new tools need to be leveraged
that allow the data to be cleaned, analyzed, and visualized quickly and efficiently. Azure
HDInsight provides one solution to this problem. HDInsight makes it simple to create
high-performance computing clusters equipped with Apache Spark and Spark ecosystem
tools. This tool allows you to focus your time on the data itself rather than deploying,
installing, configuring and maintaining the resources required to analyze the data.
Apache Spark is an open-source parallel-processing platform that excels at running
large-scale data analytics jobs. Spark’s combined use of in-memory and disk data storage
delivers performance improvements that allow it to process some tasks up to 100 times
faster than Hadoop. Azure makes deploying Spark clusters relatively simple and allows you
to work on your data analysis sooner.
In this mini-project, you’ll get hands-on experience with Apache Spark for Azure HDInsight.
After provisioning a Spark cluster, you will use the Microsoft Azure Storage Explorer to add a
Jupyter Notebook to the cluster. You will then use the notebook to explore and analyze
Walmart stock data. Your goal is to learn how to create and utilize your own Spark clusters,
provision them with Azure, and get a working introduction to Spark data analytics. <br>

# Learning Goals <br>
In this mini-project, you will learn how to: <br>
● Deploy an HDInsight Spark cluster <br>
● Work with content stored in Azure Blob Storage and accessed by the Spark cluster as an HDFS volume <br>
● Use a Jupyter Notebook to interactively explore a large dataset <br>
● Delete a Spark cluster to avoid incurring unnecessary charges <br>


# Deliverables
1. Jupyter Notebook with code to achieve stated objective in each cell <br>
2. A PPT/Word-doc with screenshots of each step as performed according to this lab <br>

